Multimodal RAG System


A Unified Framework for Text and Image-Based Document Understanding Using Retrieval-Augmented Generation

 
 
 Overview

 
This repository presents a state-of-the-art Multimodal Retrieval-Augmented Generation (MM-RAG) system that integrates both textual and visual data to enable comprehensive document analysis and intelligent question-answering. The framework is tailored to handle complex documents such as PDFs with embedded images by utilizing cutting-edge AI models.




 

 
 Dataset
The system is evaluated using two real-world educational PDFs:

"Neurology Introduction" (MUK Publications)

"Animal Cell Culture and Technology"

These documents provide both detailed text and rich visual data, ideal for testing multimodal capabilities.




Results


Accurate extraction and indexing of multimodal content

Fast, relevant information retrieval from text and images

Human-like answer generation with integrated visual cues
